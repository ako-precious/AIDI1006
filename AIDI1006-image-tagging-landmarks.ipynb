{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccad6cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Describe an Image - local =====\n",
      "Description of local image: \n",
      "'a group of people taking a selfie' with confidence 61.05%\n",
      "\n",
      "===== Describe an image - remote =====\n",
      "Description of remote image: \n",
      "'a family sitting on a couch' with confidence 57.75%\n",
      "\n",
      "===== Categorize an Image - local =====\n",
      "Categories from local image: \n",
      "'people_crowd' with confidence 32.42%\n",
      "'people_group' with confidence 43.75%\n",
      "\n",
      "===== Categorize an image - remote =====\n",
      "Categories from remote image: \n",
      "'people_group' with confidence 69.14%\n",
      "\n",
      "===== Tag an Image - local =====\n",
      "Tags in the local image: \n",
      "'person' with confidence 99.82%\n",
      "'clothing' with confidence 99.76%\n",
      "'human face' with confidence 99.38%\n",
      "'outdoor' with confidence 99.09%\n",
      "'smile' with confidence 98.83%\n",
      "'tree' with confidence 98.52%\n",
      "'happy' with confidence 96.48%\n",
      "'sky' with confidence 95.72%\n",
      "'friendship' with confidence 88.73%\n",
      "'group' with confidence 85.15%\n",
      "'social group' with confidence 85.03%\n",
      "'people' with confidence 84.31%\n",
      "'woman' with confidence 75.54%\n",
      "'posing' with confidence 71.59%\n",
      "'standing' with confidence 61.43%\n",
      "\n",
      "===== Tag an image - remote =====\n",
      "Tags in the remote image: \n",
      "'clothing' with confidence 99.92%\n",
      "'person' with confidence 99.89%\n",
      "'human face' with confidence 99.78%\n",
      "'smile' with confidence 98.11%\n",
      "'girl' with confidence 93.83%\n",
      "'indoor' with confidence 93.77%\n",
      "'people' with confidence 92.19%\n",
      "'couch' with confidence 91.33%\n",
      "'lap' with confidence 91.06%\n",
      "'social group' with confidence 90.94%\n",
      "'jeans' with confidence 90.74%\n",
      "'group' with confidence 89.23%\n",
      "'family' with confidence 89.08%\n",
      "'friendship' with confidence 87.94%\n",
      "'wall' with confidence 87.44%\n",
      "'comfort' with confidence 86.81%\n",
      "'sitting' with confidence 83.17%\n",
      "'woman' with confidence 80.58%\n",
      "'posing' with confidence 69.98%\n",
      "\n",
      "===== Detect Faces - local =====\n",
      "Faces in the local image: \n",
      "'None' of age None at location 561, 620, 775, 834\n",
      "'None' of age None at location 1472, 799, 1674, 1001\n",
      "'None' of age None at location 743, 784, 940, 981\n",
      "'None' of age None at location 1185, 571, 1367, 753\n",
      "'None' of age None at location 1364, 646, 1541, 823\n",
      "'None' of age None at location 975, 695, 1145, 865\n",
      "'None' of age None at location 1392, 971, 1561, 1140\n",
      "'None' of age None at location 1126, 857, 1292, 1023\n",
      "\n",
      "===== Detect Faces - remote =====\n",
      "Faces in the remote image: \n",
      "'None' of age None at location 118, 159, 212, 253\n",
      "'None' of age None at location 492, 111, 582, 201\n",
      "'None' of age None at location 18, 153, 102, 237\n",
      "'None' of age None at location 386, 166, 467, 247\n",
      "'None' of age None at location 235, 158, 311, 234\n",
      "'None' of age None at location 323, 163, 391, 231\n",
      "\n",
      "===== Detect Adult or Racy Content - local =====\n",
      "Analyzing local image for adult or racy content ... \n",
      "Is adult content: False with confidence 0.03\n",
      "Has racy content: False with confidence 0.07\n",
      "\n",
      "===== Detect Adult or Racy Content - remote =====\n",
      "Analyzing remote image for adult or racy content ... \n",
      "Is adult content: False with confidence 0.45\n",
      "Has racy content: False with confidence 0.56\n",
      "\n",
      "===== Detect Color - local =====\n",
      "Getting color scheme of the local image: \n",
      "Is black and white: False\n",
      "Accent color: 3A3C6C\n",
      "Dominant background color: White\n",
      "Dominant foreground color: White\n",
      "Dominant colors: ['White', 'Brown']\n",
      "\n",
      "===== Detect Color - remote =====\n",
      "Getting color scheme of the remote image: \n",
      "Is black and white: False\n",
      "Accent color: 16435F\n",
      "Dominant background color: White\n",
      "Dominant foreground color: White\n",
      "Dominant colors: ['White']\n",
      "\n",
      "===== Detect Domain-specific Content - local =====\n"
     ]
    },
    {
     "ename": "ComputerVisionErrorResponseException",
     "evalue": "(InvalidRequest) Feature is not supported. Please apply for access at https://aka.ms/celebrityrecognition",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mComputerVisionErrorResponseException\u001b[0m      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 315\u001b[0m\n\u001b[0;32m    313\u001b[0m local_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(local_image_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    314\u001b[0m \u001b[38;5;66;03m# Call API with the type of content (celebrities) and local image\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m detect_domain_results_celebs_local \u001b[38;5;241m=\u001b[39m \u001b[43mcomputervision_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_image_by_domain_in_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcelebrities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# Print which celebrities (if any) were detected\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCelebrities in the local image:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\akopr\\anaconda3\\Lib\\site-packages\\azure\\cognitiveservices\\vision\\computervision\\operations\\_computer_vision_client_operations.py:1436\u001b[0m, in \u001b[0;36mComputerVisionClientOperationsMixin.analyze_image_by_domain_in_stream\u001b[1;34m(self, model, image, language, model_version, custom_headers, raw, callback, **operation_config)\u001b[0m\n\u001b[0;32m   1433\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(request, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moperation_config)\n\u001b[0;32m   1435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m]:\n\u001b[1;32m-> 1436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m models\u001b[38;5;241m.\u001b[39mComputerVisionErrorResponseException(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize, response)\n\u001b[0;32m   1438\u001b[0m deserialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "\u001b[1;31mComputerVisionErrorResponseException\u001b[0m: (InvalidRequest) Feature is not supported. Please apply for access at https://aka.ms/celebrityrecognition"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "\n",
    "subscription_key = \"2cemQSrvr2KlcNyqBJHoj1CmxYn7aiX2wwtv6JcBtTon8Gi5KfQ4JQQJ99AKACYeBjFXJ3w3AAAFACOG0w7R\"\n",
    "endpoint = \"https://computersvission.cognitiveservices.azure.com/\"\n",
    "\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "\n",
    "# Quickstart variables // These variables are shared by several examples\n",
    "#images_folder = os.path.join (os.path.dirname(os.path.abspath(__file__)), \"images\")\n",
    "images_folder = \"C:\\\\Users\\\\akopr\\\\OneDrive\\\\Documents\\\\codes\\\\python\\\\AIDI1006\\\\images\"\n",
    "\n",
    "remote_image_url = \"https://wp.en.aleteia.org/wp-content/uploads/sites/2/2020/05/web3-family-large-big-home-brother-sister-mother-father-shutterstock_1197877477.jpg?w=640&crop=1\"\n",
    "\n",
    "\n",
    "print(\"===== Describe an Image - local =====\")\n",
    "# Open local image file\n",
    "local_image_path = os.path.join (images_folder, \"happy-family.jpg\")\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "\n",
    "# Call API\n",
    "description_result = computervision_client.describe_image_in_stream(local_image)\n",
    "\n",
    "# Get the captions (descriptions) from the response, with confidence level\n",
    "print(\"Description of local image: \")\n",
    "if (len(description_result.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_result.captions:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))\n",
    "print()\n",
    "'''\n",
    "END - Describe an Image - local\n",
    "'''\n",
    "\n",
    "'''\n",
    "Describe an Image - remote\n",
    "This example describes the contents of an image with the confidence score.\n",
    "'''\n",
    "print(\"===== Describe an image - remote =====\")\n",
    "# Call API\n",
    "description_results = computervision_client.describe_image(remote_image_url )\n",
    "\n",
    "# Get the captions (descriptions) from the response, with confidence level\n",
    "print(\"Description of remote image: \")\n",
    "if (len(description_results.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_results.captions:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))\n",
    "# </snippet_describe>\n",
    "print()\n",
    "'''\n",
    "END - Describe an Image - remote\n",
    "'''\n",
    "\n",
    "'''\n",
    "Categorize an Image -  local\n",
    "This example extracts categories from a local image with a confidence score\n",
    "'''\n",
    "print(\"===== Categorize an Image - local =====\")\n",
    "# Open local image file\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "# Select visual feature type(s)\n",
    "local_image_features = [\"categories\"]\n",
    "# Call API\n",
    "categorize_results_local = computervision_client.analyze_image_in_stream(local_image, local_image_features)\n",
    "\n",
    "# Print category results with confidence score\n",
    "print(\"Categories from local image: \")\n",
    "if (len(categorize_results_local.categories) == 0):\n",
    "    print(\"No categories detected.\")\n",
    "else:\n",
    "    for category in categorize_results_local.categories:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))\n",
    "print()\n",
    "'''\n",
    "END - Categorize an Image - local\n",
    "'''\n",
    "\n",
    "# <snippet_categorize>\n",
    "'''\n",
    "Categorize an Image - remote\n",
    "This example extracts (general) categories from a remote image with a confidence score.\n",
    "'''\n",
    "print(\"===== Categorize an image - remote =====\")\n",
    "# Select the visual feature(s) you want.\n",
    "remote_image_features = [\"categories\"]\n",
    "# Call API with URL and features\n",
    "categorize_results_remote = computervision_client.analyze_image(remote_image_url , remote_image_features)\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Categories from remote image: \")\n",
    "if (len(categorize_results_remote.categories) == 0):\n",
    "    print(\"No categories detected.\")\n",
    "else:\n",
    "    for category in categorize_results_remote.categories:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))\n",
    "# </snippet_categorize>\n",
    "print()\n",
    "'''\n",
    " END - Categorize an Image - remote\n",
    "'''\n",
    "\n",
    "'''\n",
    "Tag an Image - local\n",
    "This example returns a tag (key word) for each thing in the image.\n",
    "'''\n",
    "print(\"===== Tag an Image - local =====\")\n",
    "# Open local image file\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "# Call API local image\n",
    "tags_result_local = computervision_client.tag_image_in_stream(local_image)\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Tags in the local image: \")\n",
    "if (len(tags_result_local.tags) == 0):\n",
    "    print(\"No tags detected.\")\n",
    "else:\n",
    "    for tag in tags_result_local.tags:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))\n",
    "print()\n",
    "'''\n",
    "END - Tag an Image - local\n",
    "'''\n",
    "\n",
    "# <snippet_tags>\n",
    "'''\n",
    "Tag an Image - remote\n",
    "This example returns a tag (key word) for each thing in the image.\n",
    "'''\n",
    "print(\"===== Tag an image - remote =====\")\n",
    "# Call API with remote image\n",
    "tags_result_remote = computervision_client.tag_image(remote_image_url )\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Tags in the remote image: \")\n",
    "if (len(tags_result_remote.tags) == 0):\n",
    "    print(\"No tags detected.\")\n",
    "else:\n",
    "    for tag in tags_result_remote.tags:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))\n",
    "# </snippet_tags>\n",
    "print()\n",
    "'''\n",
    "END - Tag an Image - remote\n",
    "'''\n",
    "\n",
    "'''\n",
    "Detect Faces - local\n",
    "This example detects faces in a local image, gets their gender and age, \n",
    "and marks them with a bounding box.\n",
    "'''\n",
    "print(\"===== Detect Faces - local =====\")\n",
    "# Open local image\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "# Select visual features(s) you want\n",
    "local_image_features = [\"faces\"]\n",
    "# Call API with local image and features\n",
    "detect_faces_results_local = computervision_client.analyze_image_in_stream(local_image, local_image_features)\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Faces in the local image: \")\n",
    "if (len(detect_faces_results_local.faces) == 0):\n",
    "    print(\"No faces detected.\")\n",
    "else:\n",
    "    for face in detect_faces_results_local.faces:\n",
    "        print(\"'{}' of age {} at location {}, {}, {}, {}\".format(face.gender, face.age, \\\n",
    "        face.face_rectangle.left, face.face_rectangle.top, \\\n",
    "        face.face_rectangle.left + face.face_rectangle.width, \\\n",
    "        face.face_rectangle.top + face.face_rectangle.height))\n",
    "print()\n",
    "'''\n",
    "END - Detect Faces - local\n",
    "'''\n",
    "\n",
    "# <snippet_faces>\n",
    "'''\n",
    "Detect Faces - remote\n",
    "This example detects faces in a remote image, gets their gender and age, \n",
    "and marks them with a bounding box.\n",
    "'''\n",
    "print(\"===== Detect Faces - remote =====\")\n",
    "# Get an image with faces\n",
    "remote_image_url_faces = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/faces.jpg\"\n",
    "# Select the visual feature(s) you want.\n",
    "remote_image_features = [\"faces\"]\n",
    "# Call the API with remote URL and features\n",
    "detect_faces_results_remote = computervision_client.analyze_image(remote_image_url_faces, remote_image_features)\n",
    "\n",
    "# Print the results with gender, age, and bounding box\n",
    "print(\"Faces in the remote image: \")\n",
    "if (len(detect_faces_results_remote.faces) == 0):\n",
    "    print(\"No faces detected.\")\n",
    "else:\n",
    "    for face in detect_faces_results_remote.faces:\n",
    "        print(\"'{}' of age {} at location {}, {}, {}, {}\".format(face.gender, face.age, \\\n",
    "        face.face_rectangle.left, face.face_rectangle.top, \\\n",
    "        face.face_rectangle.left + face.face_rectangle.width, \\\n",
    "        face.face_rectangle.top + face.face_rectangle.height))\n",
    "# </snippet_faces>\n",
    "print()\n",
    "'''\n",
    "END - Detect Faces - remote\n",
    "'''\n",
    "\n",
    "'''\n",
    "Detect Adult or Racy Content - local\n",
    "This example detects adult or racy content in a local image, then prints the adult/racy score.\n",
    "The score is ranged 0.0 - 1.0 with smaller numbers indicating negative results.\n",
    "'''\n",
    "print(\"===== Detect Adult or Racy Content - local =====\")\n",
    "# Open local file\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "# Select visual features you want\n",
    "local_image_features = [\"adult\"]\n",
    "# Call API with local image and features\n",
    "detect_adult_results_local = computervision_client.analyze_image_in_stream(local_image, local_image_features)\n",
    "\n",
    "# Print results with adult/racy score\n",
    "print(\"Analyzing local image for adult or racy content ... \")\n",
    "print(\"Is adult content: {} with confidence {:.2f}\".format(detect_adult_results_local .adult.is_adult_content, detect_adult_results_local .adult.adult_score * 100))\n",
    "print(\"Has racy content: {} with confidence {:.2f}\".format(detect_adult_results_local .adult.is_racy_content, detect_adult_results_local .adult.racy_score * 100))\n",
    "print()\n",
    "'''\n",
    "END - Detect Adult or Racy Content - local\n",
    "'''\n",
    "\n",
    "# <snippet_adult>\n",
    "'''\n",
    "Detect Adult or Racy Content - remote\n",
    "This example detects adult or racy content in a remote image, then prints the adult/racy score.\n",
    "The score is ranged 0.0 - 1.0 with smaller numbers indicating negative results.\n",
    "'''\n",
    "print(\"===== Detect Adult or Racy Content - remote =====\")\n",
    "# Select the visual feature(s) you want\n",
    "remote_image_features = [\"adult\"]\n",
    "# Call API with URL and features\n",
    "detect_adult_results_remote = computervision_client.analyze_image(remote_image_url, remote_image_features)\n",
    "\n",
    "# Print results with adult/racy score\n",
    "print(\"Analyzing remote image for adult or racy content ... \")\n",
    "print(\"Is adult content: {} with confidence {:.2f}\".format(detect_adult_results_remote.adult.is_adult_content, detect_adult_results_remote.adult.adult_score * 100))\n",
    "print(\"Has racy content: {} with confidence {:.2f}\".format(detect_adult_results_remote.adult.is_racy_content, detect_adult_results_remote.adult.racy_score * 100))\n",
    "# </snippet_adult>\n",
    "print()\n",
    "'''\n",
    "END - Detect Adult or Racy Content - remote\n",
    "'''\n",
    "\n",
    "'''\n",
    "Detect Color - local\n",
    "This example detects the different aspects of its color scheme in a local image.\n",
    "'''\n",
    "print(\"===== Detect Color - local =====\")\n",
    "# Open local image\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "# Select visual feature(s) you want\n",
    "local_image_features = [\"color\"]\n",
    "# Call API with local image and features\n",
    "detect_color_results_local = computervision_client.analyze_image_in_stream(local_image, local_image_features)\n",
    "\n",
    "# Print results of the color scheme detected\n",
    "print(\"Getting color scheme of the local image: \")\n",
    "print(\"Is black and white: {}\".format(detect_color_results_local.color.is_bw_img))\n",
    "print(\"Accent color: {}\".format(detect_color_results_local.color.accent_color))\n",
    "print(\"Dominant background color: {}\".format(detect_color_results_local.color.dominant_color_background))\n",
    "print(\"Dominant foreground color: {}\".format(detect_color_results_local.color.dominant_color_foreground))\n",
    "print(\"Dominant colors: {}\".format(detect_color_results_local.color.dominant_colors))\n",
    "print()\n",
    "'''\n",
    "END - Detect Color - local\n",
    "'''\n",
    "\n",
    "# <snippet_color>\n",
    "'''\n",
    "Detect Color - remote\n",
    "This example detects the different aspects of its color scheme in a remote image.\n",
    "'''\n",
    "print(\"===== Detect Color - remote =====\")\n",
    "# Select the feature(s) you want\n",
    "remote_image_features = [\"color\"]\n",
    "# Call API with URL and features\n",
    "detect_color_results_remote = computervision_client.analyze_image(remote_image_url, remote_image_features)\n",
    "\n",
    "# Print results of color scheme\n",
    "print(\"Getting color scheme of the remote image: \")\n",
    "print(\"Is black and white: {}\".format(detect_color_results_remote.color.is_bw_img))\n",
    "print(\"Accent color: {}\".format(detect_color_results_remote.color.accent_color))\n",
    "print(\"Dominant background color: {}\".format(detect_color_results_remote.color.dominant_color_background))\n",
    "print(\"Dominant foreground color: {}\".format(detect_color_results_remote.color.dominant_color_foreground))\n",
    "print(\"Dominant colors: {}\".format(detect_color_results_remote.color.dominant_colors))\n",
    "# </snippet_color>\n",
    "print()\n",
    "'''\n",
    "END - Detect Color - remote\n",
    "'''\n",
    "\n",
    "'''\n",
    "Detect Domain-specific Content - local\n",
    "This example detects celebrites and landmarks in local images.\n",
    "'''\n",
    "print(\"===== Detect Domain-specific Content - local =====\")\n",
    "# Open local image file containing a celebtriy\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "# Call API with the type of content (celebrities) and local image\n",
    "detect_domain_results_celebs_local = computervision_client.analyze_image_by_domain_in_stream(\"celebrities\", local_image)\n",
    "\n",
    "# Print which celebrities (if any) were detected\n",
    "print(\"Celebrities in the local image:\")\n",
    "if len(detect_domain_results_celebs_local.result[\"celebrities\"]) == 0:\n",
    "    print(\"No celebrities detected.\")\n",
    "else:\n",
    "    for celeb in detect_domain_results_celebs_local.result[\"celebrities\"]:\n",
    "        print(celeb[\"name\"])\n",
    "\n",
    "# Open local image file containing a landmark\n",
    "local_image_path_landmark = os.path.join (images_folder, \"landmark.jpg\")\n",
    "local_image_landmark = open(local_image_path_landmark, \"rb\")\n",
    "# Call API with type of content (landmark) and local image\n",
    "detect_domain_results_landmark_local = computervision_client.analyze_image_by_domain_in_stream(\"landmarks\", local_image_landmark)\n",
    "print()\n",
    "\n",
    "# Print results of landmark detected\n",
    "print(\"Landmarks in the local image:\")\n",
    "if len(detect_domain_results_landmark_local.result[\"landmarks\"]) == 0:\n",
    "    print(\"No landmarks detected.\")\n",
    "else:\n",
    "    for landmark in detect_domain_results_landmark_local.result[\"landmarks\"]:\n",
    "        print(landmark[\"name\"])\n",
    "print()\n",
    "'''\n",
    "END - Detect Domain-specific Content - local\n",
    "'''\n",
    "\n",
    "# <snippet_celebs>\n",
    "'''\n",
    "Detect Domain-specific Content - remote\n",
    "This example detects celebrites and landmarks in remote images.\n",
    "'''\n",
    "print(\"===== Detect Domain-specific Content - remote =====\")\n",
    "# URL of one or more celebrities\n",
    "remote_image_url_celebs = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/faces.jpg\"\n",
    "# Call API with content type (celebrities) and URL\n",
    "detect_domain_results_celebs_remote = computervision_client.analyze_image_by_domain(\"celebrities\", remote_image_url_celebs)\n",
    "\n",
    "# Print detection results with name\n",
    "print(\"Celebrities in the remote image:\")\n",
    "if len(detect_domain_results_celebs_remote.result[\"celebrities\"]) == 0:\n",
    "    print(\"No celebrities detected.\")\n",
    "else:\n",
    "    for celeb in detect_domain_results_celebs_remote.result[\"celebrities\"]:\n",
    "        print(celeb[\"name\"])\n",
    "# </snippet_celebs>\n",
    "\n",
    "# <snippet_landmarks>\n",
    "# Call API with content type (landmarks) and URL\n",
    "detect_domain_results_landmarks = computervision_client.analyze_image_by_domain(\"landmarks\", remote_image_url)\n",
    "print()\n",
    "\n",
    "print(\"Landmarks in the remote image:\")\n",
    "if len(detect_domain_results_landmarks.result[\"landmarks\"]) == 0:\n",
    "    print(\"No landmarks detected.\")\n",
    "else:\n",
    "    for landmark in detect_domain_results_landmarks.result[\"landmarks\"]:\n",
    "        print(landmark[\"name\"])\n",
    "# </snippet_landmarks>\n",
    "print()\n",
    "'''\n",
    "END - Detect Domain-specific Content - remote\n",
    "'''\n",
    "\n",
    "'''\n",
    "Detect Image Types - local\n",
    "This example detects an image's type (clip art/line drawing).\n",
    "'''\n",
    "print(\"===== Detect Image Types - local =====\")\n",
    "# Open local image\n",
    "#local_image_path_type = os.path.join (images_folder, \"type-image.jpg\")\n",
    "local_image_path_type = \"C:\\\\images\\\\type-image.jpg\"\n",
    "local_image_type = open(local_image_path_type, \"rb\")\n",
    "# Select visual feature(s) you want\n",
    "local_image_features = [VisualFeatureTypes.image_type]\n",
    "# Call API with local image and features\n",
    "detect_type_results_local = computervision_client.analyze_image_in_stream(local_image_type, local_image_features)\n",
    "\n",
    "# Print type results with degree of accuracy\n",
    "print(\"Type of local image:\")\n",
    "if detect_type_results_local.image_type.clip_art_type == 0:\n",
    "    print(\"Image is not clip art.\")\n",
    "elif detect_type_results_local.image_type.line_drawing_type == 1:\n",
    "    print(\"Image is ambiguously clip art.\")\n",
    "elif detect_type_results_local.image_type.line_drawing_type == 2:\n",
    "    print(\"Image is normal clip art.\")\n",
    "else:\n",
    "    print(\"Image is good clip art.\")\n",
    "\n",
    "if detect_type_results_local.image_type.line_drawing_type == 0:\n",
    "    print(\"Image is not a line drawing.\")\n",
    "else:\n",
    "    print(\"Image is a line drawing\")\n",
    "print()\n",
    "'''\n",
    "END - Detect Image Types - local\n",
    "'''\n",
    "\n",
    "# <snippet_type>\n",
    "'''\n",
    "Detect Image Types - remote\n",
    "This example detects an image's type (clip art/line drawing).\n",
    "'''\n",
    "print(\"===== Detect Image Types - remote =====\")\n",
    "# Get URL of an image with a type\n",
    "remote_image_url_type = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/type-image.jpg\"\n",
    "# Select visual feature(s) you want\n",
    "remote_image_features = [VisualFeatureTypes.image_type]\n",
    "# Call API with URL and features\n",
    "detect_type_results_remote = computervision_client.analyze_image(remote_image_url_type, remote_image_features)\n",
    "\n",
    "# Prints type results with degree of accuracy\n",
    "print(\"Type of remote image:\")\n",
    "if detect_type_results_remote.image_type.clip_art_type == 0:\n",
    "    print(\"Image is not clip art.\")\n",
    "elif detect_type_results_remote.image_type.line_drawing_type == 1:\n",
    "    print(\"Image is ambiguously clip art.\")\n",
    "elif detect_type_results_remote.image_type.line_drawing_type == 2:\n",
    "    print(\"Image is normal clip art.\")\n",
    "else:\n",
    "    print(\"Image is good clip art.\")\n",
    "\n",
    "if detect_type_results_remote.image_type.line_drawing_type == 0:\n",
    "    print(\"Image is not a line drawing.\")\n",
    "else:\n",
    "    print(\"Image is a line drawing\")\n",
    "# </snippet_type>\n",
    "print()\n",
    "'''\n",
    "END - Detect Image Types - remote\n",
    "'''\n",
    "\n",
    "'''\n",
    "Detect Objects - local\n",
    "This example detects different kinds of objects with bounding boxes in a local image.\n",
    "'''\n",
    "print(\"===== Detect Objects - local =====\")\n",
    "# Get local image with different objects in it\n",
    "local_image_path_objects = os.path.join (images_folder, \"objects.jpg\")\n",
    "local_image_objects = open(local_image_path_objects, \"rb\")\n",
    "# Call API with local image\n",
    "detect_objects_results_local = computervision_client.detect_objects_in_stream(local_image_objects)\n",
    "\n",
    "# Print results of detection with bounding boxes\n",
    "print(\"Detecting objects in local image:\")\n",
    "if len(detect_objects_results_local.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results_local.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))\n",
    "print()\n",
    "'''\n",
    "END - Detect Objects - local\n",
    "'''\n",
    "\n",
    "# <snippet_objects>\n",
    "'''\n",
    "Detect Objects - remote\n",
    "This example detects different kinds of objects with bounding boxes in a remote image.\n",
    "'''\n",
    "print(\"===== Detect Objects - remote =====\")\n",
    "# Get URL image with different objects\n",
    "remote_image_url_objects = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/objects.jpg\"\n",
    "# Call API with URL\n",
    "detect_objects_results_remote = computervision_client.detect_objects(remote_image_url_objects)\n",
    "\n",
    "# Print detected objects results with bounding boxes\n",
    "print(\"Detecting objects in remote image:\")\n",
    "if len(detect_objects_results_remote.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results_remote.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))\n",
    "# </snippet_objects>\n",
    "print()\n",
    "'''\n",
    "END - Detect Objects - remote\n",
    "'''\n",
    "\n",
    "'''\n",
    "Detect Brands - local\n",
    "This example detects common brands like logos and puts a bounding box around them.\n",
    "'''\n",
    "print(\"===== Detect Brands - local =====\")\n",
    "# Open image file\n",
    "local_image_path_shirt = os.path.join (images_folder, \"gray-shirt-logo.jpg\")\n",
    "local_image_shirt = open(local_image_path_shirt, \"rb\")\n",
    "# Select the visual feature(s) you want\n",
    "local_image_features = [\"brands\"]\n",
    "# Call API with image and features\n",
    "detect_brands_results_local = computervision_client.analyze_image_in_stream(local_image_shirt, local_image_features)\n",
    "\n",
    "# Print detection results with bounding box and confidence score\n",
    "print(\"Detecting brands in local image: \")\n",
    "if len(detect_brands_results_local.brands) == 0:\n",
    "    print(\"No brands detected.\")\n",
    "else:\n",
    "    for brand in detect_brands_results_local.brands:\n",
    "        print(\"'{}' brand detected with confidence {:.1f}% at location {}, {}, {}, {}\".format( \\\n",
    "        brand.name, brand.confidence * 100, brand.rectangle.x, brand.rectangle.x + brand.rectangle.w, \\\n",
    "        brand.rectangle.y, brand.rectangle.y + brand.rectangle.h))\n",
    "print()\n",
    "'''\n",
    "END - Detect brands - local\n",
    "'''\n",
    "\n",
    "# <snippet_brands>\n",
    "'''\n",
    "Detect Brands - remote\n",
    "This example detects common brands like logos and puts a bounding box around them.\n",
    "'''\n",
    "print(\"===== Detect Brands - remote =====\")\n",
    "# Get a URL with a brand logo\n",
    "remote_image_url = \"https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/images/gray-shirt-logo.jpg\"\n",
    "# Select the visual feature(s) you want\n",
    "remote_image_features = [\"brands\"]\n",
    "# Call API with URL and features\n",
    "detect_brands_results_remote = computervision_client.analyze_image(remote_image_url, remote_image_features)\n",
    "\n",
    "print(\"Detecting brands in remote image: \")\n",
    "if len(detect_brands_results_remote.brands) == 0:\n",
    "    print(\"No brands detected.\")\n",
    "else:\n",
    "    for brand in detect_brands_results_remote.brands:\n",
    "        print(\"'{}' brand detected with confidence {:.1f}% at location {}, {}, {}, {}\".format( \\\n",
    "        brand.name, brand.confidence * 100, brand.rectangle.x, brand.rectangle.x + brand.rectangle.w, \\\n",
    "        brand.rectangle.y, brand.rectangle.y + brand.rectangle.h))\n",
    "# </snippet_brands>\n",
    "print()\n",
    "'''\n",
    "END - Detect Brands - remote\n",
    "'''\n",
    "\n",
    "'''\n",
    "Generate Thumbnail\n",
    "This example creates a thumbnail from both a local and URL image.\n",
    "'''\n",
    "print(\"===== Generate Thumbnail =====\")\n",
    "\n",
    "# Generate a thumbnail from a local image\n",
    "local_image_path_thumb = os.path.join (images_folder, \"objects.jpg\")\n",
    "local_image_thumb = open(local_image_path_objects, \"rb\")\n",
    "\n",
    "print(\"Generating thumbnail from a local image...\")\n",
    "# Call the API with a local image, set the width/height if desired (pixels)\n",
    "# Returns a Generator object, a thumbnail image binary (list).\n",
    "thumb_local = computervision_client.generate_thumbnail_in_stream(100, 100, local_image_thumb, True)\n",
    "\n",
    "# Write the image binary to file\n",
    "with open(\"thumb_local.png\", \"wb\") as f:\n",
    "    for chunk in thumb_local:\n",
    "        f.write(chunk)\n",
    "\n",
    "# Uncomment/use this if you are writing many images as thumbnails from a list\n",
    "# for i, image in enumerate(thumb_local, start=0):\n",
    "#      with open('thumb_{0}.jpg'.format(i), 'wb') as f:\n",
    "#         f.write(image)\n",
    "\n",
    "print(\"Thumbnail saved to local folder.\")\n",
    "print()\n",
    "\n",
    "# Generate a thumbnail from a URL image\n",
    "# URL of faces\n",
    "remote_image_url_thumb = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/faces.jpg\"\n",
    "\n",
    "print(\"Generating thumbnail from a URL image...\")\n",
    "# Returns a Generator object, a thumbnail image binary (list).\n",
    "thumb_remote = computervision_client.generate_thumbnail(\n",
    "    100, 100, remote_image_url_thumb, True)\n",
    "\n",
    "# Write the image binary to file\n",
    "with open(\"thumb_remote.png\", \"wb\") as f:\n",
    "    for chunk in thumb_remote:\n",
    "        f.write(chunk)\n",
    "\n",
    "print(\"Thumbnail saved to local folder.\")\n",
    "\n",
    "# Uncomment/use this if you are writing many images as thumbnails from a list\n",
    "# for i, image in enumerate(thumb_remote, start=0):\n",
    "#      with open('thumb_{0}.jpg'.format(i), 'wb') as f:\n",
    "#         f.write(image)\n",
    "\n",
    "print()\n",
    "'''\n",
    "END - Generate Thumbnail\n",
    "'''\n",
    "\n",
    "print(\"End of Computer Vision quickstart.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
